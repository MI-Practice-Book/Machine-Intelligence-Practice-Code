# 案例二：深度强化学习的行为模拟实践（多智能体）

本仓库对应课程 **案例二** 的完整实验代码，围绕 **多智能体协作控制场景下的行为学习** 展开。  
实验基于 **StarCraft II 微操任务（SMAC）**，采用 **QMIX（Value Decomposition 系列）** 多智能体强化学习算法，展示从环境验证、模型训练到结果统计与分析的完整实验流程。

与案例一不同，本案例中的 **训练过程直接采用 PyMARL 框架提供的命令行方式运行**，未对训练主流程进行额外封装；本仓库重点保留与实验复现、结果分析和行为理解 **直接相关的自编代码与实验产出**。

---

## 代码功能说明

### 1️⃣ `code1_env_check.py` —— 环境验证与接口测试

**功能说明**  
用于验证 StarCraft II、SMAC 与 PyMARL 运行环境是否配置正确，确保多智能体实验可以正常启动。

**主要内容**
- 检查 Python 运行环境  
- 验证 SMAC 环境是否可被正确加载  
- 排除路径、依赖等基础问题  

**作用**
- 避免在正式训练阶段因环境问题导致实验失败  
- 为后续多智能体训练提供可靠运行基础  

---

### 2️⃣ 训练过程（命令行运行，非独立脚本）

**说明（重要）**  
本案例中 **QMIX 训练未通过独立 Python 脚本封装**，而是直接采用 PyMARL 框架的原生命令行方式运行，例如：

```bash
python src/main.py --config=qmix --env-config=sc2 with env_args.map_name=3m
```

## 说明

- 本仓库中**不额外提供训练主程序代码**。  
- **QMIX 算法结构与训练流程由 PyMARL 框架统一管理**，实验过程中直接采用其原生命令行方式运行训练任务。  
- 本实验的重点放在 **实验配置、结果分析与行为理解** 上，而非对训练框架本身进行二次封装或重写。

---

## 3️⃣ `code3_analysis.py` —— 训练结果统计与分析

### 功能说明  
对多智能体训练过程中产生的日志数据进行整理、统计与可视化分析。

### 分析指标
- 团队胜率（Win Rate）  
- 回合长度（Episode Length）  
- 敌我单位击杀数量（Dead Enemies / Dead Allies）

### 输出结果
- 结果图像统一保存在 `analysis_figs/` 目录下  

### 作用
- 从定量角度评估多智能体协作策略的学习效果  
- 支撑实验报告中对 **QMIX 收敛行为与协作能力** 的分析  

---

## 4️⃣ `code4_record_episode.py` —— 回合记录与行为辅助分析

### 功能说明  
用于记录单个或多个回合的执行过程，辅助理解多智能体在特定情形下的决策行为。

### 主要用途
- 记录关键回合的状态与动作信息  
- 辅助调试与阶段性行为观察  

---

## 5️⃣ `code5_record_before_after_replay.py` —— 训练前后对比辅助脚本

### 功能说明  
用于在训练前后，对指定模型或训练阶段进行对比性回合记录。

### 说明
- 本实验未对 replay 文件进行系统性行为分析  
- 该脚本主要用于辅助验证与阶段性对比  
- 仓库中不强制保留 replay 文件本体  

---

## 最终文件目录如下
<img width="464" height="483" alt="image" src="https://github.com/user-attachments/assets/61f62032-1972-41a6-a6b4-db6de47aa23f" />



