# Chapter 3: åŸºäºYOLOv5çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ

## ğŸ“š é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ã€Šæœºå™¨æ™ºèƒ½ã€‹æ•™æç¬¬3ç« "ç»“æ„æ¨¡æ‹Ÿè®¾è®¡"çš„å®è·µä»»åŠ¡1,å®ç°äº†åŸºäºYOLOv5çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚é€šè¿‡æœ¬é¡¹ç›®,å­¦ä¹ è€…å°†æŒæ¡:

- VOCæ•°æ®é›†çš„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- YOLOv5æ¨¡å‹çš„è®­ç»ƒã€è¯„ä¼°å’Œæ¨ç†æµç¨‹
- ç›®æ ‡æ£€æµ‹ç³»ç»Ÿçš„å®Œæ•´å¼€å‘æµç¨‹
- æ·±åº¦å­¦ä¹ é¡¹ç›®çš„å·¥ç¨‹åŒ–å®è·µ

**å¯¹åº”æ•™æç« èŠ‚**: 3.1 å®è·µä»»åŠ¡1ï¼šYOLOv5ç›®æ ‡æ£€æµ‹

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
Task1_YOLOv5_Detection/
â”œâ”€â”€ utils/                          # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                   # æ—¥å¿—ç®¡ç†å·¥å…·
â”‚   â”œâ”€â”€ voc_converter.py            # VOCæ ¼å¼è½¬æ¢å·¥å…·
â”‚   â””â”€â”€ dataset_analyzer.py         # æ•°æ®é›†åˆ†æå·¥å…·
â”œâ”€â”€ scripts/                        # è„šæœ¬æ¨¡å—
â”‚   â”œâ”€â”€ prepare_dataset.py          # æ•°æ®é›†å‡†å¤‡ä¸»è„šæœ¬
â”‚   â”œâ”€â”€ train_yolov5.py            # è®­ç»ƒå°è£…è„šæœ¬
â”‚   â”œâ”€â”€ evaluate_model.py          # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ batch_inference.py         # æ‰¹é‡æ¨ç†è„šæœ¬
â”œâ”€â”€ configs/                        # é…ç½®æ–‡ä»¶(è¿è¡Œåç”Ÿæˆ)
â”‚   â””â”€â”€ VOC2012.yaml               # æ•°æ®é›†é…ç½®
â”œâ”€â”€ requirements.txt                # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md                       # æœ¬æ–‡ä»¶
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

**ç³»ç»Ÿè¦æ±‚**:
- Python 3.8+
- CUDA 11.3+ (GPUè®­ç»ƒ)
- 8GB+ RAM
- 20GB+ ç£ç›˜ç©ºé—´

**å®‰è£…æ­¥éª¤**:

```bash
# 1. å…‹éš†YOLOv5ä»“åº“
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
git checkout v7.0  # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ(æ¨è)
conda create -n yolov5 python=3.8
conda activate yolov5

# 3. å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.3
pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html

# CUDA 11.7
pip install torch==1.13.0+cu117 torchvision==0.14.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html

# 4. å®‰è£…YOLOv5ä¾èµ–
pip install -r requirements.txt

# 5. å®‰è£…æœ¬é¡¹ç›®ä¾èµ–
cd ../Task1_YOLOv5_Detection
pip install -r requirements.txt
```

**éªŒè¯å®‰è£…**:
```bash
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### é˜¶æ®µ1: æ•°æ®å‡†å¤‡ (å¯¹åº”æ•™æ 3.1.3èŠ‚)

**åŠŸèƒ½**: è‡ªåŠ¨ä¸‹è½½VOCæ•°æ®é›†ã€æ ¼å¼è½¬æ¢ã€è´¨é‡åˆ†æ

```bash
# å‡†å¤‡VOC2012æ•°æ®é›†(å®Œæ•´æµç¨‹)
python scripts/prepare_dataset.py \
    --data_root data \
    --year 2012

# åªè½¬æ¢æ ¼å¼(æ•°æ®å·²ä¸‹è½½)
python scripts/prepare_dataset.py \
    --data_root data \
    --year 2012 \
    --skip_download

# å‡†å¤‡VOC2007æ•°æ®é›†
python scripts/prepare_dataset.py \
    --data_root data \
    --year 2007
```

**è¾“å‡ºæ–‡ä»¶**:
```
data/
â”œâ”€â”€ VOC2012/              # åŸå§‹VOCæ•°æ®
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/           # YOLOæ ¼å¼è®­ç»ƒé›†æ ‡æ³¨
â”‚   â””â”€â”€ val/             # YOLOæ ¼å¼éªŒè¯é›†æ ‡æ³¨
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ train_analysis.json
â”‚   â””â”€â”€ val_analysis.json
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ prepare_dataset.log
â””â”€â”€ VOC2012.yaml         # YOLOv5é…ç½®æ–‡ä»¶
```

**ç›¸å…³æ¨¡å—**:
- `utils/voc_converter.py`: VOCâ†’YOLOæ ¼å¼è½¬æ¢
- `utils/dataset_analyzer.py`: æ•°æ®é›†ç»Ÿè®¡åˆ†æ

---

### é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ (å¯¹åº”æ•™æ 3.1.4èŠ‚)

**åŠŸèƒ½**: å°è£…YOLOv5è®­ç»ƒæµç¨‹,æ”¯æŒå‚æ•°åŒ–é…ç½®å’Œæ–­ç‚¹ç»­è®­

**åŸºç¡€è®­ç»ƒ**:
```bash
python scripts/train_yolov5.py \
    --yolov5_root /path/to/yolov5 \
    --data data/VOC2012.yaml \
    --img 640 \
    --batch 16 \
    --epochs 100 \
    --weights yolov5s.pt \
    --device 0 \
    --name voc_train_exp1
```

**é«˜çº§é…ç½®**:
```bash
# å¤šGPUè®­ç»ƒ + ä½™å¼¦å­¦ä¹ ç‡ + å¤šå°ºåº¦
python scripts/train_yolov5.py \
    --yolov5_root /path/to/yolov5 \
    --data data/VOC2012.yaml \
    --batch 32 \
    --epochs 300 \
    --device 0,1 \
    --optimizer AdamW \
    --lr0 0.001 \
    --cos-lr \
    --multi-scale \
    --cache ram \
    --name voc_advanced

# æ–­ç‚¹ç»­è®­
python scripts/train_yolov5.py \
    --yolov5_root /path/to/yolov5 \
    --data data/VOC2012.yaml \
    --resume \
    --name voc_train_exp1
```

**è®­ç»ƒå‚æ•°è¯´æ˜**:

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | æ•™æç« èŠ‚ |
|------|------|--------|---------|
| `--img` | è¾“å…¥å›¾åƒå°ºå¯¸ | 640 | 3.1.4 |
| `--batch` | æ‰¹æ¬¡å¤§å° | 16 | 3.1.4 |
| `--epochs` | è®­ç»ƒè½®æ•° | 100 | 3.1.4 |
| `--lr0` | åˆå§‹å­¦ä¹ ç‡ | 0.01 | 3.1.4 |
| `--optimizer` | ä¼˜åŒ–å™¨(SGD/Adam/AdamW) | SGD | 3.1.4 |
| `--cos-lr` | ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦ | False | 3.1.4 |
| `--multi-scale` | å¤šå°ºåº¦è®­ç»ƒ | False | 3.1.4 |
| `--cache` | ç¼“å­˜å›¾åƒ(ram/disk) | None | 3.1.4 |

**è¾“å‡ºæ–‡ä»¶**:
```
runs/train/voc_train_exp1/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt         # æœ€ä½³æƒé‡
â”‚   â””â”€â”€ last.pt         # æœ€ç»ˆæƒé‡
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ train_*.log     # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ train_config.json   # è®­ç»ƒé…ç½®
â”œâ”€â”€ results.png         # è®­ç»ƒæ›²çº¿
â””â”€â”€ confusion_matrix.png
```

**ç›¸å…³æ¨¡å—**:
- `scripts/train_yolov5.py`: è®­ç»ƒæµç¨‹å°è£…
- `utils/logger.py`: æ—¥å¿—å’Œæ—¶é—´ç»Ÿè®¡

---

### é˜¶æ®µ3: æ¨¡å‹è¯„ä¼° (å¯¹åº”æ•™æ 3.1.4èŠ‚)

**åŠŸèƒ½**: è®¡ç®—mAPã€ç”Ÿæˆæ··æ·†çŸ©é˜µå’ŒPRæ›²çº¿

**åŸºç¡€è¯„ä¼°**:
```bash
python scripts/evaluate_model.py \
    --yolov5_root /path/to/yolov5 \
    --weights runs/train/voc_train_exp1/weights/best.pt \
    --data data/VOC2012.yaml \
    --img 640 \
    --batch 32 \
    --device 0 \
    --name eval_exp1
```

**è°ƒæ•´é˜ˆå€¼è¯„ä¼°**:
```bash
python scripts/evaluate_model.py \
    --yolov5_root /path/to/yolov5 \
    --weights best.pt \
    --data data/VOC2012.yaml \
    --conf-thres 0.25 \
    --iou-thres 0.45 \
    --save-txt \
    --save-json \
    --verbose
```

**è¯„ä¼°æŒ‡æ ‡è¯´æ˜**:

| æŒ‡æ ‡ | å«ä¹‰ | æ•™æç« èŠ‚ |
|------|------|---------|
| Precision | ç²¾ç¡®ç‡ = TP/(TP+FP) | 3.1.4 |
| Recall | å¬å›ç‡ = TP/(TP+FN) | 3.1.4 |
| mAP@0.5 | IoU=0.5æ—¶çš„å¹³å‡ç²¾åº¦ | 3.1.4 |
| mAP@0.5:0.95 | IoUä»0.5åˆ°0.95çš„å¹³å‡mAP | 3.1.4 |
| F1-Score | ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ | 3.1.4 |

**è¾“å‡ºæ–‡ä»¶**:
```
runs/val/eval_exp1/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ eval_*.log
â”œâ”€â”€ confusion_matrix.png    # æ··æ·†çŸ©é˜µ
â”œâ”€â”€ F1_curve.png           # F1æ›²çº¿
â”œâ”€â”€ P_curve.png            # ç²¾ç¡®ç‡æ›²çº¿
â”œâ”€â”€ R_curve.png            # å¬å›ç‡æ›²çº¿
â”œâ”€â”€ PR_curve.png           # PRæ›²çº¿
â””â”€â”€ evaluation_results.json
```

**ç›¸å…³æ¨¡å—**:
- `scripts/evaluate_model.py`: æ¨¡å‹è¯„ä¼°

---

### é˜¶æ®µ4: æ¨¡å‹æ¨ç† (å¯¹åº”æ•™æ 3.1.4èŠ‚)

**åŠŸèƒ½**: æ‰¹é‡å¤„ç†å›¾åƒ/è§†é¢‘,è‡ªåŠ¨ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š

**å›¾åƒæ–‡ä»¶å¤¹æ¨ç†**:
```bash
python scripts/batch_inference.py \
    --yolov5_root /path/to/yolov5 \
    --weights runs/train/voc_train_exp1/weights/best.pt \
    --source data/images/test \
    --img 640 \
    --conf-thres 0.25 \
    --device 0 \
    --name test_infer
```

**è§†é¢‘æ¨ç†**:
```bash
python scripts/batch_inference.py \
    --yolov5_root /path/to/yolov5 \
    --weights best.pt \
    --source video.mp4 \
    --save-crop \
    --name video_detect
```

**é«˜çº§åŠŸèƒ½**:
```bash
# åªæ£€æµ‹ç‰¹å®šç±»åˆ«(person=0, car=2)
python scripts/batch_inference.py \
    --yolov5_root /path/to/yolov5 \
    --weights best.pt \
    --source images/ \
    --classes 0 2 \
    --hide-labels \
    --class-names person bicycle car motorbike

# é«˜ç½®ä¿¡åº¦ + ä¿å­˜è£å‰ª
python scripts/batch_inference.py \
    --yolov5_root /path/to/yolov5 \
    --weights best.pt \
    --source images/ \
    --conf-thres 0.5 \
    --save-crop \
    --line-thickness 2
```

**è¾“å‡ºæ–‡ä»¶**:
```
runs/detect/test_infer/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ infer_*.log
â”œâ”€â”€ labels/                    # txtæ ¼å¼æ£€æµ‹ç»“æœ
â”‚   â”œâ”€â”€ image1.txt
â”‚   â””â”€â”€ image2.txt
â”œâ”€â”€ crops/                     # è£å‰ªçš„æ£€æµ‹æ¡†
â”‚   â”œâ”€â”€ person/
â”‚   â””â”€â”€ car/
â”œâ”€â”€ image1.jpg                 # æ ‡æ³¨åçš„å›¾åƒ
â”œâ”€â”€ image2.jpg
â””â”€â”€ inference_statistics.json  # ç»Ÿè®¡æŠ¥å‘Š
```

**ç›¸å…³æ¨¡å—**:
- `scripts/batch_inference.py`: æ‰¹é‡æ¨ç†å’Œç»Ÿè®¡åˆ†æ

---

## ğŸ”§ å·¥å…·æ¨¡å—è¯¦è§£

### logger.py - æ—¥å¿—ç®¡ç†å·¥å…·

**åŠŸèƒ½**: ç»Ÿä¸€æ—¥å¿—è®°å½•ã€æ—¶é—´ç»Ÿè®¡ã€è¿›åº¦æ˜¾ç¤º

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from utils.logger import setup_logger, TaskTimer, ProgressLogger

# åˆå§‹åŒ–æ—¥å¿—
setup_logger(log_file="logs/my_task.log")

# ä»»åŠ¡è®¡æ—¶
with TaskTimer("æ•°æ®å¤„ç†"):
    # ä½ çš„ä»£ç 
    pass

# æ‰¹é‡å¤„ç†è¿›åº¦
progress = ProgressLogger(total=1000, task_name="å›¾åƒå¤„ç†")
for i in range(1000):
    # å¤„ç†å•ä¸ªå›¾åƒ
    progress.update()
progress.finish()
```

**å…³é”®ç±»**:
- `TaskTimer`: ä»»åŠ¡è®¡æ—¶å™¨,è‡ªåŠ¨è®°å½•è€—æ—¶
- `ProgressLogger`: è¿›åº¦è®°å½•å™¨,æ˜¾ç¤ºè¿›åº¦å’Œé¢„ä¼°å‰©ä½™æ—¶é—´
- `setup_logger`: é…ç½®æ—¥å¿—ç³»ç»Ÿ

---

### voc_converter.py - VOCæ ¼å¼è½¬æ¢å·¥å…·

**åŠŸèƒ½**: VOC XML â†’ YOLO txtæ ¼å¼è½¬æ¢,åæ ‡å½’ä¸€åŒ–

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from utils.voc_converter import VOCConverter

voc_classes = ['person', 'car', 'bicycle', ...]
converter = VOCConverter(class_names=voc_classes)

# æ‰¹é‡è½¬æ¢
converter.convert_dataset(
    annotations_dir=Path("VOC2012/Annotations"),
    output_dir=Path("labels/train"),
    subset='train'
)
```

**è½¬æ¢è§„åˆ™**:
```
VOCæ ¼å¼: (xmin, ymin, xmax, ymax) - ç»å¯¹åæ ‡
    â†“
YOLOæ ¼å¼: (x_center, y_center, width, height) - å½’ä¸€åŒ–åæ ‡

x_center = (xmin + xmax) / (2 Ã— img_width)
y_center = (ymin + ymax) / (2 Ã— img_height)
width = (xmax - xmin) / img_width
height = (ymax - ymin) / img_height
```

**é”™è¯¯æ£€æµ‹**:
- âœ… åæ ‡é¡ºåºæ£€æŸ¥
- âœ… åæ ‡èŒƒå›´æ£€æŸ¥
- âœ… è¾¹ç•Œæ¡†å°ºå¯¸æ£€æŸ¥
- âœ… æœªçŸ¥ç±»åˆ«æ£€æµ‹

---

### dataset_analyzer.py - æ•°æ®é›†åˆ†æå·¥å…·

**åŠŸèƒ½**: æ•°æ®ç»Ÿè®¡ã€è´¨é‡æ£€æŸ¥ã€å¯è§†åŒ–åˆ†æ

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from utils.dataset_analyzer import DatasetAnalyzer

analyzer = DatasetAnalyzer(class_names=voc_classes)

# åˆ†ææ•°æ®é›†
stats = analyzer.analyze_dataset(
    labels_dir=Path("labels/train"),
    image_size=(640, 640),
    subset='train'
)

# ä¿å­˜æŠ¥å‘Š
analyzer.save_report(Path("reports/train_analysis.json"))
```

**åˆ†æå†…å®¹**:
- åŸºæœ¬ç»Ÿè®¡(å›¾åƒæ•°ã€æ ‡æ³¨æ•°)
- ç±»åˆ«åˆ†å¸ƒå’Œä¸å¹³è¡¡æ£€æµ‹
- è¾¹ç•Œæ¡†å°ºå¯¸åˆ†å¸ƒ(å°/ä¸­/å¤§ç›®æ ‡)
- å®½é«˜æ¯”ç»Ÿè®¡
- æ•°æ®è´¨é‡é—®é¢˜æ£€æµ‹

---

## ğŸ“Š å®éªŒç»“æœç¤ºä¾‹

### VOC2012æ•°æ®é›†ç»Ÿè®¡

| å­é›† | å›¾åƒæ•° | æ ‡æ³¨æ•° | å¹³å‡æ ‡æ³¨æ•°/å›¾ |
|------|--------|--------|--------------|
| Train | 5,717 | 13,609 | 2.38 |
| Val | 5,823 | 13,841 | 2.38 |

### è®­ç»ƒç»“æœ(YOLOv5s, 100 epochs)

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| Precision | 0.847 |
| Recall | 0.783 |
| mAP@0.5 | 0.821 |
| mAP@0.5:0.95 | 0.586 |

### å„ç±»åˆ«æ€§èƒ½(Top 5)

| ç±»åˆ« | Precision | Recall | mAP@0.5 |
|------|-----------|--------|---------|
| person | 0.89 | 0.87 | 0.90 |
| car | 0.91 | 0.86 | 0.89 |
| dog | 0.88 | 0.82 | 0.87 |
| bicycle | 0.86 | 0.81 | 0.85 |
| bird | 0.84 | 0.79 | 0.83 |

---

## âš ï¸ å¸¸è§é—®é¢˜

### 1. CUDA Out of Memory

**åŸå› **: GPUæ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
--batch 8  # æˆ– 4

# å‡å°å›¾åƒå°ºå¯¸
--img 416  # æˆ– 320

# ä½¿ç”¨å›¾åƒç¼“å­˜
--cache disk
```

### 2. æ•°æ®é›†ä¸‹è½½å¤±è´¥

**åŸå› **: ç½‘ç»œé—®é¢˜æˆ–VOCæœåŠ¡å™¨ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar

# æ”¾åˆ°æŒ‡å®šç›®å½•åè·³è¿‡ä¸‹è½½
python scripts/prepare_dataset.py --skip_download
```

### 3. è®­ç»ƒä¸­æ–­ç»­è®­

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨--resumeå‚æ•°
python scripts/train_yolov5.py \
    --yolov5_root /path/to/yolov5 \
    --data data/VOC2012.yaml \
    --resume \
    --name original_exp_name  # ä½¿ç”¨åŸæ¥çš„å®éªŒåç§°
```

### 4. æ¨¡å‹è¯„ä¼°æŒ‡æ ‡åä½

**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆ**:

1. **è®­ç»ƒä¸å……åˆ†**:
   - å¢åŠ epochs: `--epochs 300`
   - ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹: `--weights yolov5m.pt`

2. **å­¦ä¹ ç‡ä¸åˆé€‚**:
   - é™ä½åˆå§‹å­¦ä¹ ç‡: `--lr0 0.005`
   - ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡: `--cos-lr`

3. **æ•°æ®å¢å¼ºä¸è¶³**:
   - ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒ: `--multi-scale`
   - å¢åŠ æ•°æ®å¢å¼º: ä¿®æ”¹hyp.yaml

4. **ç±»åˆ«ä¸å¹³è¡¡**:
   - ä½¿ç”¨å›¾åƒåŠ æƒé‡‡æ ·: éœ€è¦ä¿®æ”¹YOLOv5æºç 

---



## ğŸ”— å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [YOLOv5 GitHub](https://github.com/ultralytics/yolov5)
- [YOLOv5 å®˜æ–¹æ–‡æ¡£](https://docs.ultralytics.com/)
- [PASCAL VOC å®˜ç½‘](http://host.robots.ox.ac.uk/pascal/VOC/)

### è®ºæ–‡
- YOLOv5: [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
- YOLOv1: Redmon et al., "You Only Look Once: Unified, Real-Time Object Detection", CVPR 2016
- PASCAL VOC: Everingham et al., "The Pascal Visual Object Classes Challenge", IJCV 2010

### æ•™ç¨‹
- [YOLOv5 è®­ç»ƒè‡ªå®šä¹‰æ•°æ®é›†æ•™ç¨‹](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)
- [ç›®æ ‡æ£€æµ‹è¯„ä¼°æŒ‡æ ‡è¯¦è§£](https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173)

---

