"""
æ•°æ®é›†åˆ†æå·¥å…·
æä¾›æ•°æ®é›†ç»Ÿè®¡ã€è´¨é‡æ£€æŸ¥å’Œå¯è§†åŒ–åˆ†æåŠŸèƒ½

Author: Machine Intelligence Practice
Date: 2025-01
"""

import logging
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict, Counter
import numpy as np

from .logger import TaskTimer, ProgressLogger


class DatasetAnalyzer:
    """æ•°æ®é›†åˆ†æå™¨"""

    def __init__(self, class_names: List[str]):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
        """
        self.class_names = class_names
        self.num_classes = len(class_names)

        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_images': 0,
            'total_annotations': 0,
            'class_distribution': defaultdict(int),
            'bbox_sizes': [],
            'bbox_aspect_ratios': [],
            'annotations_per_image': [],
            'empty_images': 0,
            'problematic_images': []
        }

    def analyze_annotation_file(self, label_file: Path, image_size: Tuple[int, int] = (640, 640)) -> Dict:
        """
        åˆ†æå•ä¸ªæ ‡æ³¨æ–‡ä»¶

        Args:
            label_file: YOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶è·¯å¾„
            image_size: å›¾åƒå°ºå¯¸ (width, height)

        Returns:
            è¯¥æ–‡ä»¶çš„åˆ†æç»“æœ
        """
        img_width, img_height = image_size
        file_stats = {
            'num_annotations': 0,
            'classes': [],
            'bbox_areas': [],
            'has_issue': False,
            'issues': []
        }

        try:
            if not label_file.exists():
                file_stats['has_issue'] = True
                file_stats['issues'].append("æ–‡ä»¶ä¸å­˜åœ¨")
                return file_stats

            with open(label_file, 'r') as f:
                lines = f.readlines()

            if len(lines) == 0:
                file_stats['has_issue'] = True
                file_stats['issues'].append("ç©ºæ–‡ä»¶")
                self.stats['empty_images'] += 1
                return file_stats

            for line_idx, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue

                try:
                    parts = line.split()
                    if len(parts) != 5:
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œæ ¼å¼é”™è¯¯")
                        continue

                    class_id = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])

                    # éªŒè¯ç±»åˆ«ID
                    if class_id < 0 or class_id >= self.num_classes:
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œç±»åˆ«IDè¶Šç•Œ: {class_id}")
                        continue

                    # éªŒè¯åæ ‡èŒƒå›´
                    if not (0 <= x_center <= 1 and 0 <= y_center <= 1):
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œä¸­å¿ƒç‚¹åæ ‡è¶Šç•Œ")
                        continue

                    if not (0 < width <= 1 and 0 < height <= 1):
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œå®½é«˜è¶Šç•Œ")
                        continue

                    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                    file_stats['num_annotations'] += 1
                    file_stats['classes'].append(class_id)

                    # è®¡ç®—å®é™…åƒç´ å°ºå¯¸
                    actual_width = width * img_width
                    actual_height = height * img_height
                    area = actual_width * actual_height
                    aspect_ratio = actual_width / actual_height if actual_height > 0 else 0

                    file_stats['bbox_areas'].append(area)

                    # å…¨å±€ç»Ÿè®¡
                    self.stats['class_distribution'][class_id] += 1
                    self.stats['bbox_sizes'].append((actual_width, actual_height))
                    self.stats['bbox_aspect_ratios'].append(aspect_ratio)

                    # æ£€æµ‹å¼‚å¸¸å°ºå¯¸
                    if actual_width < 10 or actual_height < 10:
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œè¾¹ç•Œæ¡†è¿‡å°")

                    if aspect_ratio > 10 or aspect_ratio < 0.1:
                        file_stats['has_issue'] = True
                        file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œå®½é«˜æ¯”å¼‚å¸¸: {aspect_ratio:.2f}")

                except ValueError as e:
                    file_stats['has_issue'] = True
                    file_stats['issues'].append(f"ç¬¬{line_idx + 1}è¡Œæ•°æ®è§£æé”™è¯¯: {e}")
                    continue

            self.stats['annotations_per_image'].append(file_stats['num_annotations'])
            self.stats['total_annotations'] += file_stats['num_annotations']

        except Exception as e:
            file_stats['has_issue'] = True
            file_stats['issues'].append(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            logging.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {label_file.name}: {e}")

        return file_stats

    def analyze_dataset(
            self,
            labels_dir: Path,
            image_size: Tuple[int, int] = (640, 640),
            subset: str = 'train'
    ) -> Dict:
        """
        åˆ†ææ•´ä¸ªæ•°æ®é›†

        Args:
            labels_dir: æ ‡æ³¨æ–‡ä»¶ç›®å½•
            image_size: å›¾åƒå°ºå¯¸
            subset: æ•°æ®é›†å­é›†åç§°

        Returns:
            åˆ†æç»Ÿè®¡ç»“æœ
        """
        with TaskTimer(f"åˆ†æ{subset}é›†"):
            # è·å–æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
            label_files = list(labels_dir.glob('*.txt'))

            if len(label_files) == 0:
                logging.warning(f"æœªæ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶: {labels_dir}")
                return self.stats

            logging.info(f"æ‰¾åˆ° {len(label_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")

            # é‡ç½®ç»Ÿè®¡æ•°æ®
            self.stats['total_images'] = len(label_files)

            # æ‰¹é‡åˆ†æ
            progress = ProgressLogger(total=len(label_files), task_name=f"{subset}é›†åˆ†æ")

            for label_file in label_files:
                file_stats = self.analyze_annotation_file(label_file, image_size)

                if file_stats['has_issue']:
                    self.stats['problematic_images'].append({
                        'filename': label_file.name,
                        'issues': file_stats['issues']
                    })

                progress.update()

            progress.finish()

            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            self._generate_report(subset)

            return self.stats.copy()

    def _generate_report(self, subset: str):
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š

        Args:
            subset: æ•°æ®é›†å­é›†åç§°
        """
        logging.info("=" * 70)
        logging.info(f"{subset}é›†æ•°æ®åˆ†ææŠ¥å‘Š")
        logging.info("=" * 70)

        # åŸºæœ¬ç»Ÿè®¡
        logging.info("\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        logging.info(f"  æ€»å›¾åƒæ•°: {self.stats['total_images']}")
        logging.info(f"  æ€»æ ‡æ³¨æ•°: {self.stats['total_annotations']}")
        logging.info(f"  ç©ºæ ‡æ³¨å›¾åƒæ•°: {self.stats['empty_images']}")
        logging.info(f"  é—®é¢˜å›¾åƒæ•°: {len(self.stats['problematic_images'])}")

        if self.stats['total_images'] > 0:
            avg_annotations = self.stats['total_annotations'] / self.stats['total_images']
            logging.info(f"  å¹³å‡æ¯å¼ å›¾åƒæ ‡æ³¨æ•°: {avg_annotations:.2f}")

        # ç±»åˆ«åˆ†å¸ƒ
        logging.info("\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
        class_dist = self.stats['class_distribution']

        if len(class_dist) > 0:
            # æŒ‰æ•°é‡æ’åº
            sorted_classes = sorted(class_dist.items(), key=lambda x: x[1], reverse=True)

            for class_id, count in sorted_classes:
                class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"æœªçŸ¥ç±»åˆ«{class_id}"
                percentage = (count / self.stats['total_annotations']) * 100
                logging.info(f"  {class_name:15s}: {count:6d} ({percentage:5.2f}%)")

            # ç±»åˆ«ä¸å¹³è¡¡æ£€æµ‹
            max_count = sorted_classes[0][1]
            min_count = sorted_classes[-1][1]
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')

            if imbalance_ratio > 10:
                logging.warning(f"  âš ï¸ æ£€æµ‹åˆ°ç±»åˆ«ä¸å¹³è¡¡! æœ€å¤§/æœ€å°æ¯”ä¾‹: {imbalance_ratio:.2f}")

        # è¾¹ç•Œæ¡†å°ºå¯¸åˆ†æ
        if len(self.stats['bbox_sizes']) > 0:
            logging.info("\nğŸ“ è¾¹ç•Œæ¡†å°ºå¯¸åˆ†æ:")

            widths = [size[0] for size in self.stats['bbox_sizes']]
            heights = [size[1] for size in self.stats['bbox_sizes']]
            areas = [w * h for w, h in self.stats['bbox_sizes']]

            logging.info(f"  å®½åº¦ - å¹³å‡: {np.mean(widths):.2f}, ä¸­ä½æ•°: {np.median(widths):.2f}, "
                         f"èŒƒå›´: [{np.min(widths):.2f}, {np.max(widths):.2f}]")
            logging.info(f"  é«˜åº¦ - å¹³å‡: {np.mean(heights):.2f}, ä¸­ä½æ•°: {np.median(heights):.2f}, "
                         f"èŒƒå›´: [{np.min(heights):.2f}, {np.max(heights):.2f}]")
            logging.info(f"  é¢ç§¯ - å¹³å‡: {np.mean(areas):.2f}, ä¸­ä½æ•°: {np.median(areas):.2f}")

            # å°ºå¯¸åˆ†å¸ƒ
            small_boxes = sum(1 for a in areas if a < 32 * 32)
            medium_boxes = sum(1 for a in areas if 32 * 32 <= a < 96 * 96)
            large_boxes = sum(1 for a in areas if a >= 96 * 96)

            total_boxes = len(areas)
            logging.info(f"  å°ç›®æ ‡ (<32Â²): {small_boxes} ({small_boxes / total_boxes * 100:.2f}%)")
            logging.info(f"  ä¸­ç›®æ ‡ (32Â²~96Â²): {medium_boxes} ({medium_boxes / total_boxes * 100:.2f}%)")
            logging.info(f"  å¤§ç›®æ ‡ (â‰¥96Â²): {large_boxes} ({large_boxes / total_boxes * 100:.2f}%)")

        # å®½é«˜æ¯”åˆ†æ
        if len(self.stats['bbox_aspect_ratios']) > 0:
            logging.info("\nğŸ“ å®½é«˜æ¯”åˆ†æ:")
            aspect_ratios = self.stats['bbox_aspect_ratios']
            logging.info(f"  å¹³å‡: {np.mean(aspect_ratios):.2f}")
            logging.info(f"  ä¸­ä½æ•°: {np.median(aspect_ratios):.2f}")
            logging.info(f"  èŒƒå›´: [{np.min(aspect_ratios):.2f}, {np.max(aspect_ratios):.2f}]")

            extreme_ratios = sum(1 for r in aspect_ratios if r > 5 or r < 0.2)
            if extreme_ratios > 0:
                logging.warning(
                    f"  âš ï¸ æç«¯å®½é«˜æ¯”æ•°é‡: {extreme_ratios} ({extreme_ratios / len(aspect_ratios) * 100:.2f}%)")

        # é—®é¢˜å›¾åƒåˆ—è¡¨
        if len(self.stats['problematic_images']) > 0:
            logging.info(f"\nâš ï¸ é—®é¢˜å›¾åƒè¯¦æƒ… (å‰10ä¸ª):")
            for item in self.stats['problematic_images'][:10]:
                logging.info(f"  {item['filename']}:")
                for issue in item['issues']:
                    logging.info(f"    - {issue}")

        logging.info("=" * 70 + "\n")

    def save_report(self, output_file: Path):
        """
        ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°JSONæ–‡ä»¶

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        report = {
            'total_images': self.stats['total_images'],
            'total_annotations': self.stats['total_annotations'],
            'empty_images': self.stats['empty_images'],
            'class_distribution': dict(self.stats['class_distribution']),
            'problematic_images_count': len(self.stats['problematic_images']),
            'problematic_images': self.stats['problematic_images'][:50]  # åªä¿å­˜å‰50ä¸ª
        }

        # ç»Ÿè®¡ä¿¡æ¯
        if len(self.stats['bbox_sizes']) > 0:
            widths = [size[0] for size in self.stats['bbox_sizes']]
            heights = [size[1] for size in self.stats['bbox_sizes']]

            report['bbox_statistics'] = {
                'width': {
                    'mean': float(np.mean(widths)),
                    'median': float(np.median(widths)),
                    'min': float(np.min(widths)),
                    'max': float(np.max(widths))
                },
                'height': {
                    'mean': float(np.mean(heights)),
                    'median': float(np.median(heights)),
                    'min': float(np.min(heights)),
                    'max': float(np.max(heights))
                }
            }

        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logging.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    from .logger import setup_logger

    # æµ‹è¯•ä»£ç 
    setup_logger(log_file="logs/dataset_analyzer_test.log")

    # VOCç±»åˆ«
    voc_classes = [
        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
        'bus', 'car', 'cat', 'chair', 'cow',
        'diningtable', 'dog', 'horse', 'motorbike', 'person',
        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
    ]

    analyzer = DatasetAnalyzer(class_names=voc_classes)

    logging.info("æ•°æ®é›†åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")